e : batch : loss           : train 1 : train 5 
1 : 50 : 245.1079020500183 : 0.0156 : 0.0684
1 : 100 : 232.59947872161865 : 0.020900000000000002 : 0.0857
1 : 150 : 225.15481090545654 : 0.025466666666666665 : 0.104
2 : 50 : 219.30075979232788 : 0.044 : 0.1634
2 : 100 : 213.28665494918823 : 0.049800000000000004 : 0.1802
2 : 150 : 209.36688351631165 : 0.05266666666666667 : 0.19073333333333334
3 : 50 : 203.71414399147034 : 0.0696 : 0.2466
3 : 100 : 199.39468455314636 : 0.07730000000000001 : 0.2626
3 : 150 : 196.93152022361755 : 0.07973333333333334 : 0.2706
4 : 50 : 192.69735956192017 : 0.0956 : 0.3178
4 : 100 : 189.29695558547974 : 0.1003 : 0.3271
4 : 150 : 185.35448718070984 : 0.10573333333333333 : 0.3380666666666667
5 : 50 : 180.01363158226013 : 0.1272 : 0.3932
5 : 100 : 177.3480532169342 : 0.1364 : 0.3997
5 : 150 : 175.52215266227722 : 0.13933333333333334 : 0.40446666666666664
6 : 50 : 167.9026379585266 : 0.1696 : 0.4552
6 : 100 : 165.64334630966187 : 0.1694 : 0.4618
6 : 150 : 166.6888027191162 : 0.17133333333333334 : 0.46626666666666666
7 : 50 : 156.33719873428345 : 0.2054 : 0.5292
7 : 100 : 156.38800883293152 : 0.2064 : 0.5305
7 : 150 : 156.10426449775696 : 0.2084 : 0.5298
8 : 50 : 146.6214599609375 : 0.2482 : 0.5794
8 : 100 : 146.36792635917664 : 0.24860000000000002 : 0.5804
8 : 150 : 145.81584930419922 : 0.248 : 0.5812666666666667
9 : 50 : 133.21412992477417 : 0.2986 : 0.646
9 : 100 : 136.40941739082336 : 0.292 : 0.6378
9 : 150 : 135.50211715698242 : 0.2912666666666667 : 0.6368
10 : 50 : 122.60975527763367 : 0.3396 : 0.694
10 : 100 : 125.6368191242218 : 0.3393 : 0.6876
10 : 150 : 123.1795563697815 : 0.3424 : 0.6882
